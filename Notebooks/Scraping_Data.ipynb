{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Scraping Proyek Fundamental Deep Learning**\n",
        "- **Nama:** Muhammad Makarim\n",
        "- **Email:** mmakarim9@student.ub.ac.id\n",
        "- **ID Dicoding:** MC006D5Y1427"
      ],
      "metadata": {
        "id": "AMPk9DOvD4xz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scraping Data dan Import Library**"
      ],
      "metadata": {
        "id": "Lw3yIV1_Ze3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada Bagian ini, dilakukan beberapa langkah persiapan yang penting untuk menjalankan scraping menggunakan `google-play-scraper` di lingkungan Google Colab:\n",
        "\n",
        "Update Paket Sistem Operasi\n",
        "\n",
        "1.   Perintah `!apt-get update` digunakan untuk memperbarui informasi paket pada sistem operasi Linux yang menjalankan Google Colab.\n",
        "2.   Instalasi Library Python. Perintah !pip install selenium scikit-learn pandas matplotlib memasang beberapa pustaka Python:\n",
        "     \n",
        "     *   `google-play-scraper` untuk scraping data ulasan aplikasi dan informasi lain dari Google Play Store secara langsung tanpa browser otomatisasi.\n",
        "     *   `pandas` untuk manipulasi dan analisis data dalam bentuk DataFrame;"
      ],
      "metadata": {
        "id": "1yPV_I2KZrtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTwtmI4Qe6Sm",
        "outputId": "7f6f2b8c-e84d-4e1a-9ecc-f448196e03bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,683 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,730 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,966 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,387 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,540 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,944 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,245 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,552 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [77.3 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,255 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Fetched 31.9 MB in 4s (9,056 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-play-scraper pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PNYRZJOdgxC",
        "outputId": "e73f619f-cd2e-4e05-dab9-129498831829"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import library yang diperlukan\n",
        "import pandas as pd\n",
        "from google_play_scraper import reviews_all, Sort"
      ],
      "metadata": {
        "id": "QSgIf9wFd4MD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scraping Data Ulasan Aplikasi WhatsApp**"
      ],
      "metadata": {
        "id": "t2DrrAyQfk_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada baguan scraping data ulasan aplkasi WhatsApp, ada beberapa langkah:\n",
        "1.   Fungsi `scraping_whatsapp_reviews()`\n",
        "  *   Memanggil fungsi reviews_all dengan parameter: `app_id='com.whatsapp`' ID aplikasi WhatsApp di Google Play Store, `lang='id'` mengambil ulasan yang berbahasa Indonesia, `country='id'` dari pengguna yang berada di Indonesia, `sort=Sort.NEWEST` mengurutkan ulasan berdasarkan yang terbaru.\n",
        "  *   Data hasil scraping berupa list dictionary diubah ke dalam DataFrame pandas.\n",
        "  *   Memilih kolom penting, yaitu `content` (isi ulasan) dan `score` (rating bintang).\n",
        "  *   Menyimpan DataFrame ke file CSV dengan nama `whatsapp_reviews.cs`v agar bisa digunakan untuk analisis lebih lanjut.\n",
        "\n",
        "2.   Menjalankan Fungsi dan Menampilkan Data\n",
        "  *   Fungsi `scraping_whatsapp_reviews()` dipanggil dan hasilnya disimpan dalam variabel `df_whatsapp_reviews`.\n",
        "  *   Menampilkan beberapa baris teratas dari data ulasan yang sudah di-scrape untuk memastikan proses berjalan dengan baik."
      ],
      "metadata": {
        "id": "BSMBXYWQfqKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi scraping ulasan aplikasi WhatsApp\n",
        "def scraping():\n",
        "    # Mengambil semua ulasan terbaru\n",
        "    result = reviews_all(\n",
        "        app_id='com.whatsapp',  # ID aplikasi WhatsApp\n",
        "        lang='id',              # Bahasa Indonesia\n",
        "        country='id',           # Lokasi Indonesia\n",
        "        count=20000,            # Jumlah maksimal ulasan yang diambil\n",
        "        sort=Sort.NEWEST        # Urutan ulasan berdasarkan yang terbaru\n",
        "    )\n",
        "\n",
        "    # Konversi ke DataFrame\n",
        "    df = pd.DataFrame(result)\n",
        "\n",
        "    # Ambil kolom isi ulasan dan rating\n",
        "    df = df[['content', 'score']]\n",
        "\n",
        "    # Simpan hasil scraping ke file CSV\n",
        "    df.to_csv(\"WhatsApp_review.csv\", index=False)\n",
        "    print(\"Data successfully saved to WhatsApp_review.csv\")\n",
        "\n",
        "scraping()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2MSnzvleDs2",
        "outputId": "30443cc6-3c5b-4103-8928-ea5c5a929aea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to WhatsApp_review.csv\n"
          ]
        }
      ]
    }
  ]
}